# 数字类型

关于数字类型我想先简单讲下其在内存中的存储，然后通过Java和JavaScript中数字类型的划分来进一步说明。

####正整数

首先我我们用二进制表示一个数字，比如123。


123 = 1+2+8+16+32+64 


123 = 1\*2<sup>0</sup>+1\*2<sup>1</sup>+0\*2<sup>2</sup>+1\*2<sup>3</sup>+1\*2<sup>4</sup>+1\*2<sup>5</sup>+1\*2<sup>6</sup>

换作二进制表示为：1111011，低位从右向左排序，即右边第一个数字表示2<sup>0</sup>。

我们以Java的short类型为例，short类型采用16位存储一个数字，目前存储数字123需要使用7位空间，还剩下9位，剩余的高位(左侧)用0来填充，因此最终表示为`00000000 01111011`。同理如果你用int类型来存储的话就是一长串的0：`00000000 00000000 00000000 01111011`，因为int类型用32为来存储一个数字。

####负整数与符号位

如果你还记得初中数学课本里讲的数轴就能猜到如何表示负数，没错，因为正数和负数是对称的，所以我们只需要在正数的基础上加上一个符号就可以了，这个符号就是符号位，符号位在最高位，这样一个16位的short类型能表示的正整数就只能折半了，即2<sup>15</sup>个，所以short类型正整数能表示的最大值就是2<sup>15</sup>-1 = 32767。

方便理解我们用3位来说明：

| 正整数| 二进制 | 负整数| 二进制 | 
| -- | -- | -- | -- |
| 1 | 001 | -1  | 101 |
| 2 | 010 | -2  | 110 |
| 3 | 011 | -3  | 111 |
| 0 | 000 | -0  | 100 |
可以看出3位能表达的正整数为2<sup>3-1</sup>-1=3个数。

####负整数与补码
只说数据类型不说类型间的运算是无意义的。接下来我们看下正整数的加减运算如何处理。

这里以4+7为例来说明加法运算：
<pre>
+4:  0| 0 1 0 0     
(+)           
+7:  0| 0 1 1 1
_______________
=    0| 1 0 1 1

+11: +| 8+0+2+1
</pre>

以12-9为例来说明减法运算：

<pre>
+12: 0| 1 1 0 0
(-)           
+9:  0| 1 0 0 1
_______________
=    0| 0 0 1 1

+3:  0| 0+0+2+1
</pre>

可以看出正整数加减法和我们想要的结果是一致的。

接下来看下负整数加减法，这里说明下负整数与负整数加减运算不运算符号位。

以(-8)+(-6)为例说明加法
<pre>
-8:  1| 1 0 0 0     
(+)           
-6:  1| 0 1 1 0
_______________
=    1| 1 1 1 0

-14: -| 8+4+2+0
</pre>

以(-6)-(-5)为例
<pre>
-6:  1| 0 1 1 0     
(-)           
-5:  1| 0 1 0 1
_______________
=    1| 0 0 0 1

-1:  -| 0+0+0+1
</pre>

好极了，到目前为止都是理想中的结果，那么接下来看个不如人意的例子。
<pre>

-3: 1| 0 0 1 1     
(+)           
+3: 0| 0 0 1 1
______________
=   1| 0 1 1 0

-6: -| 0+4+2+0
</pre>

可以看出-3+3=-6这是不正确的运算结果，我们期待的结果应该是
-3+3=0。这里为了得到正确的结果，我们先反向构造出一个和为0的情况：
<pre>
-3: 1| 0 0 1 1     
(+)           
+3: 0| 1 1 0 1
______________
=   1| 0 0 0 0

0: -| 0+0+0+0
</pre>

可以看出`0011`按位取反在加1*2<sup>0</sup>=1即为`1101`，这里按位取反再加一后得到的`1101`就是`0011`的补码。我们可以通过补码的定义修补数学意义上相反数和为零的漏洞。

接下来我们用补码来表示负数

| 正整数| 二进制 | 负整数| 二进制 | 
| -- | -- | -- | -- |
| 1 | 001 | -1  | 111 |
| 2 | 010 | -2  | 110 |
| 3 | 011 | -3  | 101 |
| 0 | 000 | -0  | 100 |

因为000已经可以表示0了所以为了避免资源的浪费我们可以用100表示-4，这样一来一个有符号的、16位的、补码表示的类型就可以表示2<sup>15</sup>-1个正整数和2<sup>15</sup>个负整数了，范围就是[ -32768 - 32767 ]。

####小数和精度

二进制与十进制的小数转换同整数一样。我们用110.11来说明二进制小数到十进制的转换。

110.11 = 1 * 2<sup>2</sup>+1 * 2<sup>1</sup>+0 * 2<sup>0</sup>+1 * 2<sup>-1</sup>+1 * 2<sup>-2</sup> = 6.75

十进制小数转换为二进制，规则为
1. 将小数位乘以二。
2. 取结果的整数位，作为高位。
3. 取结果的小数位重复上述操作，如果结果小数位为0则结束运算。

我们将0.725转换为二进制。

1. 0.125 * 2 = 0.25，取整为0，取0.25循环。
2. 0.25*2 = 0.5， 取整为0， 取0.5循环。
3. 0.5*2 = 1.0，取整为1，取0结束。
4. 按顺序拼接取整后数字到高位：001。

这样0.625表示为二进制就是001。
对于小数的存储，常见的方式有32位和64位两种。
在32位中把第32位作为符号位，第31位到23位这8位作为小数位，剩下的23位用来表示整数。
在64位中把第64位作为符号位，第63到52位这11位作为小数位，剩下的52位用来表示整数。
以上小数存储规则可以参考IEEE754规范。

####小数运算误差

如果你尝试过用二进制表示0.3或者0.2就会发现，即使用64位（双精度）来表示，其实也只能是一个近似值，因为0.3这种小数是无法通过有限位的二进制表示的。

这样就引出了一个有趣的问题，我们以JavaScript来说明，在JavaScript中所有数字都是按照64位（11位小数位，52位整数位）方式存储的，这样我们得到0.3,0.2,0.1的二进制表示如下：
```
0.3： 0.0100 1100 110
0.2： 0.0011 0011 001
0.1： 0.0001 1001 100
```
我们取0.3与0.2的后三位做减法与0.1的后三位比较
```
0.3-0.2:  101
0.1:      100
```
很明显两者是不相等的，所以如下代码是合乎情理的。
```javascript
//JavaScript 0.2-0.3 != 0.1

0.3 - 0.2 === 0.2 - 0.1;  
//false
```
这不是任何一门编程语言的问题，这是采用了IEEE754规范的计算机语言都兼备的问题。所以在计算机程序运算中尽可能采用小单位运算，比如`0.3T = 300KG`，因为你知道的计算机存储300要比存储0.3准确的多。

基本的数字存储说完后，我们看看不同语言对数字类型的划分是什么样的：

####Java的数字类型

|名称 | 类型 | 位数 | 符号位 | 范围 |
| -- | -- | -- | -- | -- | -- |
|字节型| byte | 8 | 有 | [-128, 127] |
|短整型| short | 16 | 有 | [-32768, -32767]|
|整型| int | 32 | 有 |[-2<sup>31</sup>, 2<sup>31</sup>-1]
|长整型| long | 64 | 有 |[-2<sup>63</sup>, 2<sup>63</sup>-1]
|浮点型| float | 32 |有| IEEE 754 binary floating point |
|双精度浮点型| double | 64 | 有 | IEEE 754 binary floating point |


1. 一般小计量的数字存储，可以用byte和short来节省内存开支。
2. 对于货币这种需要精确数值的，不能用float和double，可以用Java提供的BigDecimal类。
3. 在Java8以后int和long可以用来表示无符号位的整数，取值范围分别为：[0, 2<sup>32</sup>-1]，[0, 2<sup>64</sup>-1]

####其他语言数字类型

我们以Java的数字类型为标准，来对比下其他语言的数字类型在定义上有什么区别。

**JavaScript和Ruby**

同Java不同，JavaScript和Ruby这样的弱类型语言，本身数字类型没有做特别细致的划分，它们用Number类型表示数字。但细节处理上JavaScript和Ruby又是不同的。

JavaScript并没有区分整数和小数，所有的数字都是遵循IEEE 754 标准采用64位flaot进行表示，而Ruby本身则是有区分Integer（Integer又分为Fixnum和Bignum）、Float和Rational（实数，类似于Java的BigDecimal类）的。

**Python**

对比Ruby提供的实数类型，Python和R则提供了一个更广泛的数据类型：complex number（复数类型），它表示为a+bj的形式，其中a和b都是浮点类型，a表示实部，b表示虚部。

另外Python的数字类型还包括int、long和float，这一点和Ruby其实是相似的，不同的是Python的long类型是没有长度限制的，而int类型超过长度限制则会转换为long类型（这就是为什么有人会说Python只有long和float两种数字类型）。

**基于JVM的二代语言**

另外像Scala、Groovy这种基于JVM的二代语言，其数字类型是沿用自Java的，无非是Scala作为弱类型语言提供了类型推断机制，在使用数字类型时无需特别声明。

另外一门基于JVM的Lisp语言方言Clojure，它没有效仿Java的数字类型，而是采用了Integers和Float两种类型，其中Integers又区分为Decimal Integers（整数类型）、Octal Numbers（八进制数）、Hexadecimal Numbers（十六进制数）、Radix Numbers（进制类型）。类似的Perl语言也提供了Hexadecimal（十六进制）和Octal（八进制）两种类型。

Clojure的进制类型可以把任意进制数转换为十进制数，因此如果你用的语言提供了这样的类型，在处理进制转换时相当方便。

这里单独说明下Clojure的进制类型，上面我们讲过了二进制的算法，同八进制和十六进制的计算方法是类似的。只是为了和十进制区分，八进制以0开头，而十六进制以0x开头。
```
0175
0x1A
```
我们将这两个数字表示为10进制：
```
0175  = 1 * 8<sup>2</sup> + 7 * 8<sup>1</sup> + 5 * 8<sup>0</sup> = 125
0x2EA = 2 * 16<sup>2</sup> + 14 * 16<sup>1</sup> + 10 * 16<sup>0</sup> = 746
```
注意16进制中用A表示10，B表示11，C表示12，依此类推，所以E表示14。而Clojure的Radix Numbers可以定义进制的底数，比如刚刚的0175就可以表示为8r175，0x2EA就可以表示为16r2ea，r前表示底数，r后表示数字。因为数字从0-9共10个，字母从a-z共26个，所以底数的范围是1-36，即Clojure的Radix Numbers最高可以计算36进制数转换。
```Clojure
(println (format "%s" 11r12)))    ;;=> 13
```
**微软系语言F#、C#、VB.net**

我们以C#为例说明，微乳除了提供了像Java数字类型中byte、short、int、long、double、float这些类型外，还特别针对有符号的short、int、long分别提供了无符号的ushort、uint、ulong类型，这些类型都无法表示负整数，但相反的却可以表示两倍于对应符号类型的正整数。












